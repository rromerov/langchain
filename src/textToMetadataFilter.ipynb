{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Metadata Filter\n",
    "\n",
    "For this example let's use *Chroma* as the vector store. Let's create a demo set of documents that contain summaries of movies\n",
    "\n",
    "First run this command to create a isolated environment with all the dependencies needed to run this example.\n",
    "\n",
    "\n",
    "\n",
    "```CMD\t\n",
    "# Creating a virtual environment to work with all features and avoid issues with dependencies\n",
    "! virtualenv venv\n",
    "```\n",
    "\n",
    "Installing necessary dependencies:    \n",
    "```CMD\n",
    "! pip install --upgrade --quiet lark langchain-chroma langchain-ollama langchain ipykernel langchain-core langchain-community\n",
    "```\n",
    "\n",
    "Create requirements file\n",
    "```CMD\n",
    "! pip freeze > ../requirements.txt\n",
    "```\n",
    "\n",
    "> Note: Running multiple times this setup leads to generating several copies of the same retrived documents, for more persistent ways to store and access the data, check [here](https://python.langchain.com/docs/integrations/vectorstores/chroma/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem brooks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "model = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "vectorstore = Chroma.from_documents(docs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='48b15bb8-570b-4164-919d-4acb1a01b5d1', metadata={'director': 'Andrei Tarkovsky', 'genre': 'thriller', 'rating': 9.9, 'year': 1979}, page_content='Three men walk into the Zone, three men walk out of the Zone'),\n",
       " Document(id='8c56d1c4-a900-4dd1-a78c-7c26bf6c7994', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie\",\n",
    "        type = \"string of list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "description = \"Summary of a movie\"\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", num_predict=100)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectorstore, description, fields, enable_limit=True,\n",
    ")\n",
    "\n",
    "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a retriever that will take a user query, and split it into:\n",
    "- A filter to apply on the metadata of each document first.\n",
    "- A query to use for semantic search on the documents.\n",
    "\n",
    "To do this, we have to describe which fields the metadata of our documents contain; that description will be included in the propmt. The retriever will then do the following:\n",
    "\n",
    "1. Send the query generation prompt to the LLM. \n",
    "2. Parse metadata filter and rewritten search query from the LLM output.\n",
    "3. Convert the metadata filter generated by the LLM to the format appropiate for our vector store.\n",
    "4. Issue a similarity search against the vector store, filtered to only match documents whose metadata passes the generated filter.\n",
    "\n",
    "> Note: After doing several changes to prompt and model configuration, notice errors related to wrong output parsing with langchain, this can be fixed by changing the prompt to be more specific about the output format. Llama3.1 has some limitations, could be a good idea to test this script with other models like Llama2 or GPT4.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
