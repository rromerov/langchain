{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da0cde6",
   "metadata": {},
   "source": [
    "# Supervisor Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c7f33",
   "metadata": {},
   "source": [
    "In this architecture, we add each agent to the graph as a node and also add a supervisor node, which decides which agents should be called next. We use conditional edges to route execution to the appropriate agent node based on the supervisor’s decision.\n",
    "\n",
    "Let’s first see what the supervisor node looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e81a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from utils import graph_to_image\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "model = AzureChatOpenAI(azure_deployment=\"gpt-4o\", api_version=\"2024-10-21\", model=\"gpt-4o\", temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision)\n",
    "\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"Given the conversation above, who should act next? Or \n",
    "    should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
    "\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", system_prompt_part_2)\n",
    "    ]\n",
    "    return model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2743561",
   "metadata": {},
   "source": [
    "> **Note**\n",
    ">\n",
    "> The code in the supervisor prompt relies on the assumption that the names of your subagents are **self-explanatory and distinct**.\n",
    ">\n",
    "> For example, if agents were named generically as `agent_1` and `agent_2`,  \n",
    "> the LLM would not have enough information to determine which one is appropriate for a given task.\n",
    ">\n",
    "> To improve selection accuracy, consider **modifying the prompt** to include a short **description**  \n",
    "> of each agent's capabilities. This can guide the LLM when making routing decisions.\n",
    "\n",
    "Now let’s look at how to integrate the supervisor node into a larger graph that includes two subagents:\n",
    "\n",
    "- `researcher`\n",
    "- `coder`\n",
    "\n",
    "The purpose of this setup is to handle queries that:\n",
    "\n",
    "- Can be answered by the **researcher** alone\n",
    "- Can be answered by the **coder** alone\n",
    "- May require **both agents in succession**\n",
    "\n",
    "This example doesn’t include implementations of the `researcher` or `coder` nodes themselves.  \n",
    "They could be any LangGraph graphs or nodes, depending on your specific use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98562f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "model = AzureChatOpenAI(azure_deployment=\"gpt-4o\", api_version=\"2024-10-21\", model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    next: Literal[\"researcher\",\"coder\", \"FINISH\"]\n",
    "\n",
    "def researcher(state: AgentState):\n",
    "    response = model.invoke(...)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def coder(state: AgentState):\n",
    "    response = model.invoke(...)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(supervisor)\n",
    "builder.add_node(researcher)\n",
    "builder.add_node(coder)\n",
    "\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "# route to one of the agents or exit based on the supervisor's decision\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"])\n",
    "builder.add_edge(\"researcher\", \"supervisor\")\n",
    "builder.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "supervisor = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86890539",
   "metadata": {},
   "source": [
    "**A Few Things to Notice**\n",
    "\n",
    "In this example, both subagents (`researcher` and `coder`) can **see each other’s work**,  \n",
    "since all progress is stored in a shared `messages` list.\n",
    "\n",
    "However, this isn’t the only way to structure a multi-agent system.\n",
    "\n",
    "---\n",
    "\n",
    "**Alternative Agent Designs**\n",
    "\n",
    "Each subagent can be more complex. For example:\n",
    "\n",
    "- A subagent could be implemented as its **own LangGraph graph**.\n",
    "- It could maintain **internal state** and return only a **summary** of its actions.\n",
    "- This allows for modular, nested graphs with encapsulated logic.\n",
    "\n",
    "---\n",
    "\n",
    "**Routing Back to the Supervisor**\n",
    "\n",
    "After each agent completes its task, the flow routes back to the **supervisor node**.  \n",
    "The supervisor then decides whether:\n",
    "\n",
    "- More work is needed\n",
    "- Another agent should be called\n",
    "- The interaction should end\n",
    "\n",
    "---\n",
    "\n",
    "**Flexible Routing Options**\n",
    "\n",
    "This back-to-supervisor design is **not a hard requirement**.\n",
    "\n",
    "You could instead allow **each agent** to decide whether its output is final.  \n",
    "To support this:\n",
    "\n",
    "- Replace the direct edge (e.g., from `researcher` to `supervisor`) with a **conditional edge**.\n",
    "- This edge would check a **state key** updated by the agent to determine what happens next.\n",
    "\n",
    "This design increases flexibility and reduces supervisor overhead for certain tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95af68df",
   "metadata": {},
   "source": [
    "Let's go back to the [main file](../README.md#patterns-to-make-the-most-of-llms)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
