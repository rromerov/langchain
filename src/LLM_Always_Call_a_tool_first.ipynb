{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "570ef424",
   "metadata": {},
   "source": [
    "# Always calling a Tool First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0c97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Annotated, TypedDict\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolCall\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Go up one level from \"notebooks/\" to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.display_graph import graph_to_image\n",
    "\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"A simple calculator tool. Input should be a mathematical expression.\"\"\"\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "model = AzureChatOpenAI(azure_deployment=\"gpt-4o\",\n",
    "                        api_version=\"2024-10-21\",\n",
    "                        model=\"gpt-4o\" #for tracing\n",
    "                        ).bind_tools(tools) #bind tools as using bind method is just for one tool\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    res = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\":res}\n",
    "\n",
    "def first_model(state: State) -> State:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    search_tool_call = ToolCall(\n",
    "        name=\"duckduckgo_search\", args={\"query\":query}, id=uuid4().hex\n",
    "    )\n",
    "    return {\"messages\": AIMessage(content=\"\", tool_calls=[search_tool_call])}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"first_model\",first_model)\n",
    "builder.add_node(\"model\", model_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"first_model\")\n",
    "builder.add_edge(\"first_model\", \"tools\")\n",
    "builder.add_conditional_edges(\"model\",tools_condition)\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16fe5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File graph_rag_for_tool_choosing.png already exists. Skipping image generation.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_to_image(graph, \"graph_rag_for_tool_choosing.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caee544",
   "metadata": {},
   "source": [
    "![Tool first agent](../img/graph_tool_first.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15ac40",
   "metadata": {},
   "source": [
    "\n",
    "This version of the agent architecture introduces a small but impactful change in how execution begins:\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Step 1: `first_model` Node\n",
    "\n",
    "- This node **does not call an LLM**.\n",
    "- Instead, it **automatically generates a tool call** to the `search` tool.\n",
    "- It uses the **user's message verbatim** as the search query.\n",
    "\n",
    "In contrast, the previous architecture relied on the **LLM to decide** whether to call the search tool or not.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Step 2: `tools` Node\n",
    "\n",
    "- This node is **identical** to the previous architecture.\n",
    "- It executes the `search` tool and returns the results.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ¤– Step 3: `agent` Node\n",
    "\n",
    "- Now the system enters the LLM loop.\n",
    "- From this point forward, the LLM **decides what to do next**, based on the results of the initial tool execution.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Why This Matters\n",
    "\n",
    "By initiating the search manually:\n",
    "- You reduce **latency** by skipping the first LLM decision step.\n",
    "- You ensure that **search always runs first**, increasing consistency.\n",
    "- You eliminate the risk of the LLM **skipping a crucial tool call**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¤ Example Output\n",
    "\n",
    "Next, letâ€™s take a look at the output for the same query used earlier, now following this updated execution flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b620de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_model': {'messages': AIMessage(content='', additional_kwargs={}, response_metadata={}, id='0ed645d0-63bc-4254-bab2-36b3999b2c1c', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'How old was the 30th president of the United States \\n            when he died?'}, 'id': '7c6daa8d0f684f4dbc2092015b04c592', 'type': 'tool_call'}])}}\n",
      "{'tools': {'messages': [ToolMessage(content='Calvin Coolidge (born John Calvin Coolidge Jr.; [1] / Ëˆ k uË l Éª dÊ’ / KOOL-ij; July 4, 1872 - January 5, 1933) was the 30th president of the United States, serving from 1923 to 1929.A Republican lawyer from Massachusetts, he previously served as the 29th vice president from 1921 to 1923 under President Warren G. Harding, and as the 48th governor of Massachusetts from 1919 to 1921. Calvin Coolidge was the 30th president of the United States (1923-29). Coolidge acceded to the presidency after the death in office of Warren G. Harding, just as the Harding scandals were coming to light. ... 1872, Plymouth, Vermont, U.S.â€”died January 5, 1933, Northampton, Massachusetts) was the 30th president of the United States (1923 ... Calvin Coolidge was the 30th president of the United States, known for his quiet demeanor and remarkable economic policies during the 1920s. Born on July 4, 1872, in Plymouth Notch, Vermont, he rose through various local and state positions, ultimately becoming the Vice President under Warren G. Harding. John Calvin Coolidge, Jr. (July 4, 1872 - January 5, 1933) was the 30th President of the United States (1923-1929). A lawyer from Vermont, Coolidge worked his way up the ladder of Massachusetts state politics, eventually becoming governor of that state. Calvin Coolidge was the 30th President of the United States, serving from 1923 to 1929. He is known for his quiet demeanor, small-government policies, and presidency during a period of economic prosperity known as the \"Roaring Twenties.\" ... Coolidge died of a heart attack on January 5, 1933, at the age of 60. ... (1923-1929), Calvin ...', name='duckduckgo_search', id='62ee7cd4-d3ee-4d59-a77f-065b48061f76', tool_call_id='7c6daa8d0f684f4dbc2092015b04c592')]}}\n",
      "{'model': {'messages': AIMessage(content='The 30th president of the United States, Calvin Coolidge, was born on July 4, 1872, and died on January 5, 1933. He was 60 years old at the time of his death.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 588, 'total_tokens': 639, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BaSasnlyvPyu0h1tWHhIERDJCskCL', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--60dceebd-7bb6-4439-a1b1-2af09d5a9c9e-0', usage_metadata={'input_tokens': 588, 'output_tokens': 51, 'total_tokens': 639, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"\"\"How old was the 30th president of the United States \n",
    "            when he died?\"\"\")\n",
    "    ]\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c25a1b",
   "metadata": {},
   "source": [
    "Note how this time, we skipped the initial LLM call. Used instead *first model* node which directly returned a tool call for the search tool. From there the same process was used as in the previous flow. We first executed the search tool and finally went back to the **model** node to generate the final anwser.\n",
    "\n",
    "Let's see another usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c27b4",
   "metadata": {},
   "source": [
    "## Dealing with Many Tools\n",
    "Large Language Models (LLMs) are powerfulâ€”but not flawless. One known limitation is their difficulty with **handling too many options** or **overly verbose prompts**.\n",
    "\n",
    "This issue is particularly evident when it comes to **planning the next tool to use**.\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Problem: Too Many Tools\n",
    "\n",
    "When presented with **more than 10 tools**, an LLMâ€™s ability to:\n",
    "- Select the correct tool\n",
    "- Plan actions effectively\n",
    "\n",
    "...begins to **decline noticeably**.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Solution: Use a RAG-Based Tool Selector\n",
    "\n",
    "If your application relies on **many specialized tools**, a better approach is to:\n",
    "1. Use a **Retrieval-Augmented Generation (RAG)** step to:\n",
    "   - Preselect the most relevant tools based on the user query.\n",
    "2. Present **only that smaller subset** to the LLM.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Benefits of This Strategy\n",
    "\n",
    "- âœ… **Improved Planning**: LLM focuses on fewer, more relevant choices.\n",
    "- âœ… **Lower Costs**: Commercial LLM pricing is often based on **prompt + output token length**.\n",
    "- âœ… **Reduced Prompt Complexity**: Easier to interpret and debug.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ•’ Tradeoff: Additional Latency\n",
    "\n",
    "- â— This RAG pre-selection step **adds overhead** to your application's runtime.\n",
    "- ðŸ“‰ Use it **only when** you notice degraded performance due to too many tools.\n",
    "\n",
    "---\n",
    "\n",
    "Letâ€™s now walk through how to implement this tool-reduction strategy using a RAG component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a374f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores.in_memory import InMemoryVectorStore\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"A simple calculator tool. Input should be a mathematical expression.\"\"\"\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "model = AzureChatOpenAI(azure_deployment=\"gpt-4o\",\n",
    "                        api_version=\"2024-10-21\",\n",
    "                        model=\"gpt-4o\" #for tracing\n",
    "                        )\n",
    "tools_retriever = InMemoryVectorStore.from_documents(\n",
    "    [Document(tool.description, metadata={\"name\": tool.name}) for tool in tools],\n",
    "    embeddings\n",
    ").as_retriever()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    selected_tools: list\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    selected_tools = [\n",
    "        tool for tool in tools if tool.name in state[\"selected_tools\"]\n",
    "    ]\n",
    "    res = model.bind_tools(selected_tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\":res}\n",
    "\n",
    "def select_tools(state: State) -> State:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    tool_docs = tools_retriever.invoke(query)\n",
    "    return {\"selected_tools\": [doc.metadata[\"name\"] for doc in tool_docs]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"select_tools\", select_tools)\n",
    "builder.add_node(\"model\", model_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"select_tools\")\n",
    "builder.add_edge(\"select_tools\", \"model\")\n",
    "builder.add_conditional_edges(\"model\",tools_condition)\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b71969b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File graph_rag_for_tool_choosing.png already exists. Skipping image generation.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_to_image(graph,\"graph_rag_for_tool_choosing.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32b3e4",
   "metadata": {},
   "source": [
    "The visual representation can be seen here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3f04d",
   "metadata": {},
   "source": [
    "![Calling tool first](../img/graph_rag_for_tool_choosing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890a2ae",
   "metadata": {},
   "source": [
    "> ### ðŸ”Ž Note\n",
    ">\n",
    "> This approach is **very similar** to the standard agent architecture.\n",
    ">\n",
    "> The **only difference** is the inclusion of a `select_tools` node **before** entering the agent loop.\n",
    ">\n",
    "> - The `select_tools` node performs a **RAG-based tool selection** step.\n",
    "> - After this, the flow continues exactly as in the **regular agent architecture**:\n",
    ">   - LLM decides what to do.\n",
    ">   - Tools are executed.\n",
    ">   - Loop continues until the stop condition is met.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe77d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'select_tools': {'selected_tools': ['duckduckgo_search', 'calculator']}}\n",
      "{'model': {'messages': AIMessage(content='The 30th president of the United States was Calvin Coolidge. He was born on July 4, 1872, and he died on January 5, 1933. Calvin Coolidge was **60 years old** when he passed away.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 116, 'total_tokens': 170, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BbtKljc6YnnjFpxmdpxR52RkpLCBW', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--b8e5575d-3440-4584-b3d8-c8240fa10d8d-0', usage_metadata={'input_tokens': 116, 'output_tokens': 54, 'total_tokens': 170, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "  \"messages\": [\n",
    "    HumanMessage(\"\"\"How old was the 30th president of the United States when \n",
    "        he died?\"\"\")\n",
    "  ]\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d52728",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "The first step in this modified agent architecture is querying the retriever  \n",
    "to get the most relevant tools for the current user query.\n",
    "\n",
    "Once the subset of relevant tools is selected, the flow proceeds into  \n",
    "the standard agent architecture, where:\n",
    "\n",
    "- The LLM selects actions based on the current context and available tools.\n",
    "- The selected tools are executed.\n",
    "- The loop continues until the stop condition is met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264d0b8",
   "metadata": {},
   "source": [
    "Let's go back to the main [file](../README.md/#more-agent-architectures)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
